{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7aec702c818eaea9bc40486a4c9f3335d27b6eb6"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "In the end of this kernel I want to have:\n",
    "XGB and Mixture Bayes trained on 2/3-3/4 data\n",
    "Neural net then trained on the remaining 1/3-1/4 data and inputs from the previous ones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import trange\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "551617ef16f86e7963a9480e827b9505bbe3dea0"
   },
   "outputs": [],
   "source": [
    "plt.style.use('bmh')\n",
    "plt.rcParams['figure.figsize'] = (10, 10)\n",
    "title_config = {'fontsize': 20, 'y': 1.05}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "8826a0440a70fbfb83138609e95d6e54eca34b69"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "c5af79fa0ce669e1716d62aae38b895508dddc1b"
   },
   "outputs": [],
   "source": [
    "X_a = train.iloc[:, 2:].values.astype('float64')\n",
    "y_a = train['target'].values\n",
    "y_a = y_a.astype('int')\n",
    "X_test = test.iloc[:, 1:].values.astype('float64')\n",
    "from sklearn.model_selection import train_test_split as ttsplit\n",
    "X_train, X_val, y_train, y_val = ttsplit(X_a, y_a, test_size=0.2)\n",
    "X_train_s1, X_train_s2, y_train_s1, y_train_s2 = ttsplit(X_train, y_train, test_size=0.3)\n",
    "\n",
    "#Above lines were there to validate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_a, y_a = augment(X_a, y_a) seriously I wrote that\n",
    "X_train_s1, X_train_s2, y_train_s1, y_train_s2 = ttsplit(X_a, y_a, test_size=0.15)\n",
    "\n",
    "y_train_s1 = y_train_s1.astype('int')\n",
    "y_train_s2 = y_train_s2.astype('int')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 200)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_a.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The code for GaussianMixtureNB has been forked.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "aecd1133cf77d4718a0b4eabf450a02e64a24e36"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.special import logsumexp\n",
    "\n",
    "\n",
    "class GaussianMixtureNB(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_components=1, reg_covar=1e-06):\n",
    "        self.n_components = n_components\n",
    "        self.reg_covar = reg_covar\n",
    "    def fit(self, X, y):\n",
    "        self.log_prior_ = np.log(np.bincount(y) / len(y))\n",
    "        # shape of self.log_pdf_\n",
    "        shape = (len(self.log_prior_), X.shape[1])\n",
    "        self.log_pdf_ = [[GaussianMixture(n_components=self.n_components,\n",
    "                                          reg_covar=self.reg_covar)\n",
    "                          .fit(X[y == i, j:j + 1])\n",
    "                          .score_samples for j in range(shape[1])]\n",
    "                         for i in range(shape[0])]\n",
    "    def predict_proba(self, X):\n",
    "        # shape of log_likelihood before summing\n",
    "        shape = (len(self.log_prior_), X.shape[1], X.shape[0])\n",
    "        log_likelihood = np.sum([[self.log_pdf_[i][j](X[:, j:j + 1])\n",
    "                                  for j in range(shape[1])]\n",
    "                                 for i in range(shape[0])], axis=1).T\n",
    "        log_joint = self.log_prior_ + log_likelihood\n",
    "        return np.exp(log_joint - logsumexp(log_joint, axis=1, keepdims=True))\n",
    "    def predict(self, X):\n",
    "        return self.predict_proba(X).argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "36425ff2d1fd2d011e2635419a538bf775055a36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training AUC is 0.9030119060143509.\n",
      "Validation AUC is 0.9023875277015142.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score, log_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "pipeline = make_pipeline(StandardScaler(), GaussianMixtureNB(n_components=3, reg_covar=0.03))\n",
    "pipeline.fit(X_train_s1, y_train_s1)\n",
    "print(f'Training AUC is {roc_auc_score(y_train, pipeline.predict_proba(X_train)[:, 1])}.')\n",
    "print(f'Validation AUC is {roc_auc_score(y_val, pipeline.predict_proba(X_val)[:, 1])}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And Mixture Bayes works well, now xgb, hyperparameters have been optimised separately.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(X_train_s1, y_train_s1)\n",
    "dval = xgb.DMatrix(X_train_s2, y_train_s2) #okay this really shouldn't make it overfit. Although I could still reshuffle etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.5741\teval-auc:0.581519\n",
      "Multiple eval metrics have been passed: 'eval-auc' will be used for early stopping.\n",
      "\n",
      "Will train until eval-auc hasn't improved in 300 rounds.\n",
      "[100]\ttrain-auc:0.696713\teval-auc:0.691902\n",
      "[200]\ttrain-auc:0.741607\teval-auc:0.734317\n",
      "[300]\ttrain-auc:0.777759\teval-auc:0.768738\n",
      "[400]\ttrain-auc:0.799551\teval-auc:0.790622\n",
      "[500]\ttrain-auc:0.814091\teval-auc:0.804421\n",
      "[600]\ttrain-auc:0.824951\teval-auc:0.814626\n",
      "[700]\ttrain-auc:0.835465\teval-auc:0.824356\n",
      "[800]\ttrain-auc:0.842413\teval-auc:0.830781\n",
      "[900]\ttrain-auc:0.849093\teval-auc:0.836222\n",
      "[1000]\ttrain-auc:0.854774\teval-auc:0.841081\n",
      "[1100]\ttrain-auc:0.859913\teval-auc:0.845322\n",
      "[1200]\ttrain-auc:0.863771\teval-auc:0.848303\n",
      "[1300]\ttrain-auc:0.867589\teval-auc:0.851603\n",
      "[1400]\ttrain-auc:0.870806\teval-auc:0.853908\n",
      "[1500]\ttrain-auc:0.873785\teval-auc:0.856339\n",
      "[1600]\ttrain-auc:0.876075\teval-auc:0.858102\n",
      "[1700]\ttrain-auc:0.878848\teval-auc:0.86042\n",
      "[1800]\ttrain-auc:0.881176\teval-auc:0.862305\n",
      "[1900]\ttrain-auc:0.88343\teval-auc:0.864264\n",
      "[2000]\ttrain-auc:0.88548\teval-auc:0.865994\n",
      "[2100]\ttrain-auc:0.887136\teval-auc:0.86723\n",
      "[2200]\ttrain-auc:0.889111\teval-auc:0.868746\n",
      "[2300]\ttrain-auc:0.890585\teval-auc:0.870171\n",
      "[2400]\ttrain-auc:0.89202\teval-auc:0.871418\n",
      "[2500]\ttrain-auc:0.893329\teval-auc:0.872475\n",
      "[2600]\ttrain-auc:0.894654\teval-auc:0.873553\n",
      "[2700]\ttrain-auc:0.895874\teval-auc:0.874539\n",
      "[2800]\ttrain-auc:0.897156\teval-auc:0.875625\n",
      "[2900]\ttrain-auc:0.898116\teval-auc:0.876299\n",
      "[3000]\ttrain-auc:0.899224\teval-auc:0.877334\n",
      "[3100]\ttrain-auc:0.900216\teval-auc:0.878154\n",
      "[3200]\ttrain-auc:0.901176\teval-auc:0.878984\n",
      "[3300]\ttrain-auc:0.902158\teval-auc:0.879739\n",
      "[3400]\ttrain-auc:0.903019\teval-auc:0.880285\n",
      "[3500]\ttrain-auc:0.903877\teval-auc:0.880987\n",
      "[3600]\ttrain-auc:0.904682\teval-auc:0.881627\n",
      "[3700]\ttrain-auc:0.905422\teval-auc:0.882211\n",
      "[3800]\ttrain-auc:0.906138\teval-auc:0.882679\n",
      "[3900]\ttrain-auc:0.906798\teval-auc:0.883231\n",
      "[4000]\ttrain-auc:0.907482\teval-auc:0.883821\n",
      "[4100]\ttrain-auc:0.908149\teval-auc:0.884287\n",
      "[4200]\ttrain-auc:0.90878\teval-auc:0.884776\n",
      "[4300]\ttrain-auc:0.909356\teval-auc:0.885291\n",
      "[4400]\ttrain-auc:0.909926\teval-auc:0.885637\n",
      "[4500]\ttrain-auc:0.910461\teval-auc:0.886053\n",
      "[4600]\ttrain-auc:0.911043\teval-auc:0.886513\n",
      "[4700]\ttrain-auc:0.911585\teval-auc:0.887064\n",
      "[4800]\ttrain-auc:0.912104\teval-auc:0.887405\n",
      "[4900]\ttrain-auc:0.912586\teval-auc:0.887822\n",
      "[5000]\ttrain-auc:0.913053\teval-auc:0.888187\n",
      "[5100]\ttrain-auc:0.913527\teval-auc:0.888591\n",
      "[5200]\ttrain-auc:0.91393\teval-auc:0.888818\n",
      "[5300]\ttrain-auc:0.914421\teval-auc:0.889148\n",
      "[5400]\ttrain-auc:0.914844\teval-auc:0.889507\n",
      "[5500]\ttrain-auc:0.915292\teval-auc:0.889874\n",
      "[5600]\ttrain-auc:0.915656\teval-auc:0.890178\n",
      "[5700]\ttrain-auc:0.916005\teval-auc:0.890452\n",
      "[5800]\ttrain-auc:0.916367\teval-auc:0.890678\n",
      "[5900]\ttrain-auc:0.916713\teval-auc:0.890867\n",
      "[6000]\ttrain-auc:0.917086\teval-auc:0.891125\n",
      "[6100]\ttrain-auc:0.917421\teval-auc:0.891333\n",
      "[6200]\ttrain-auc:0.917768\teval-auc:0.891601\n",
      "[6300]\ttrain-auc:0.918114\teval-auc:0.891906\n",
      "[6400]\ttrain-auc:0.918428\teval-auc:0.892112\n",
      "[6500]\ttrain-auc:0.918735\teval-auc:0.892285\n",
      "[6600]\ttrain-auc:0.919031\teval-auc:0.892428\n",
      "[6700]\ttrain-auc:0.919323\teval-auc:0.892595\n",
      "[6800]\ttrain-auc:0.919614\teval-auc:0.892762\n",
      "[6900]\ttrain-auc:0.919915\teval-auc:0.89291\n",
      "[7000]\ttrain-auc:0.920188\teval-auc:0.893068\n",
      "[7100]\ttrain-auc:0.92044\teval-auc:0.893231\n",
      "[7200]\ttrain-auc:0.920676\teval-auc:0.89336\n",
      "[7300]\ttrain-auc:0.920941\teval-auc:0.893543\n",
      "[7400]\ttrain-auc:0.921203\teval-auc:0.893691\n",
      "[7500]\ttrain-auc:0.921458\teval-auc:0.893867\n",
      "[7600]\ttrain-auc:0.921719\teval-auc:0.894054\n",
      "[7700]\ttrain-auc:0.921951\teval-auc:0.894182\n",
      "[7800]\ttrain-auc:0.922162\teval-auc:0.894276\n",
      "[7900]\ttrain-auc:0.922393\teval-auc:0.894398\n",
      "[8000]\ttrain-auc:0.922637\teval-auc:0.894489\n",
      "[8100]\ttrain-auc:0.922859\teval-auc:0.894589\n",
      "[8200]\ttrain-auc:0.923066\teval-auc:0.894668\n",
      "[8300]\ttrain-auc:0.923302\teval-auc:0.894815\n",
      "[8400]\ttrain-auc:0.923503\teval-auc:0.894933\n",
      "[8500]\ttrain-auc:0.923722\teval-auc:0.895081\n",
      "[8600]\ttrain-auc:0.923917\teval-auc:0.895183\n",
      "[8700]\ttrain-auc:0.924116\teval-auc:0.895309\n",
      "[8800]\ttrain-auc:0.92431\teval-auc:0.895406\n",
      "[8900]\ttrain-auc:0.924505\teval-auc:0.895504\n",
      "[9000]\ttrain-auc:0.92468\teval-auc:0.89561\n",
      "[9100]\ttrain-auc:0.924854\teval-auc:0.895687\n",
      "[9200]\ttrain-auc:0.925052\teval-auc:0.895743\n",
      "[9300]\ttrain-auc:0.925232\teval-auc:0.895852\n",
      "[9400]\ttrain-auc:0.925418\teval-auc:0.895924\n",
      "[9500]\ttrain-auc:0.925595\teval-auc:0.896036\n",
      "[9600]\ttrain-auc:0.925762\teval-auc:0.896079\n",
      "[9700]\ttrain-auc:0.925944\teval-auc:0.896165\n",
      "[9800]\ttrain-auc:0.926118\teval-auc:0.896234\n",
      "[9900]\ttrain-auc:0.926273\teval-auc:0.896287\n",
      "[10000]\ttrain-auc:0.926442\teval-auc:0.896328\n",
      "[10100]\ttrain-auc:0.926615\teval-auc:0.896406\n",
      "[10200]\ttrain-auc:0.926776\teval-auc:0.896418\n",
      "[10300]\ttrain-auc:0.926934\teval-auc:0.896466\n",
      "[10400]\ttrain-auc:0.927087\teval-auc:0.896533\n",
      "[10500]\ttrain-auc:0.927242\teval-auc:0.896567\n",
      "[10600]\ttrain-auc:0.92739\teval-auc:0.896644\n",
      "[10700]\ttrain-auc:0.927522\teval-auc:0.896678\n",
      "[10800]\ttrain-auc:0.927663\teval-auc:0.896737\n",
      "[10900]\ttrain-auc:0.927817\teval-auc:0.896752\n",
      "[11000]\ttrain-auc:0.927957\teval-auc:0.896755\n",
      "[11100]\ttrain-auc:0.928105\teval-auc:0.8968\n",
      "[11200]\ttrain-auc:0.928243\teval-auc:0.896827\n",
      "[11300]\ttrain-auc:0.928381\teval-auc:0.896852\n",
      "[11400]\ttrain-auc:0.928515\teval-auc:0.896884\n",
      "[11500]\ttrain-auc:0.928659\teval-auc:0.896917\n",
      "[11600]\ttrain-auc:0.928799\teval-auc:0.896974\n",
      "[11700]\ttrain-auc:0.928926\teval-auc:0.897023\n",
      "[11800]\ttrain-auc:0.929063\teval-auc:0.897019\n",
      "[11900]\ttrain-auc:0.929198\teval-auc:0.897033\n",
      "[12000]\ttrain-auc:0.929335\teval-auc:0.897056\n",
      "[12100]\ttrain-auc:0.929473\teval-auc:0.897133\n",
      "[12200]\ttrain-auc:0.929603\teval-auc:0.897183\n",
      "[12300]\ttrain-auc:0.929744\teval-auc:0.897204\n",
      "[12400]\ttrain-auc:0.929869\teval-auc:0.897239\n",
      "[12500]\ttrain-auc:0.929996\teval-auc:0.897259\n",
      "[12600]\ttrain-auc:0.930115\teval-auc:0.897287\n",
      "[12700]\ttrain-auc:0.930235\teval-auc:0.897299\n",
      "[12800]\ttrain-auc:0.930365\teval-auc:0.89733\n",
      "[12900]\ttrain-auc:0.930493\teval-auc:0.897357\n",
      "[13000]\ttrain-auc:0.930614\teval-auc:0.897396\n",
      "[13100]\ttrain-auc:0.930731\teval-auc:0.897397\n",
      "[13200]\ttrain-auc:0.930854\teval-auc:0.897441\n",
      "[13300]\ttrain-auc:0.930971\teval-auc:0.897454\n",
      "[13400]\ttrain-auc:0.931108\teval-auc:0.897506\n",
      "[13500]\ttrain-auc:0.931239\teval-auc:0.897517\n",
      "[13600]\ttrain-auc:0.931367\teval-auc:0.897524\n",
      "[13700]\ttrain-auc:0.931496\teval-auc:0.897539\n",
      "[13800]\ttrain-auc:0.931626\teval-auc:0.897542\n",
      "[13900]\ttrain-auc:0.931742\teval-auc:0.897573\n",
      "[14000]\ttrain-auc:0.931865\teval-auc:0.897568\n",
      "[14100]\ttrain-auc:0.931984\teval-auc:0.897587\n",
      "[14200]\ttrain-auc:0.932102\teval-auc:0.897613\n",
      "[14300]\ttrain-auc:0.93223\teval-auc:0.897673\n",
      "[14400]\ttrain-auc:0.932352\teval-auc:0.897675\n",
      "[14500]\ttrain-auc:0.932466\teval-auc:0.897675\n",
      "[14600]\ttrain-auc:0.932591\teval-auc:0.897672\n",
      "[14700]\ttrain-auc:0.932711\teval-auc:0.897681\n",
      "[14800]\ttrain-auc:0.932834\teval-auc:0.897697\n",
      "[14900]\ttrain-auc:0.932966\teval-auc:0.897719\n",
      "[15000]\ttrain-auc:0.933092\teval-auc:0.897715\n",
      "[15100]\ttrain-auc:0.933215\teval-auc:0.89774\n",
      "[15200]\ttrain-auc:0.933337\teval-auc:0.8978\n",
      "[15300]\ttrain-auc:0.933457\teval-auc:0.897811\n",
      "[15400]\ttrain-auc:0.933585\teval-auc:0.897822\n",
      "[15500]\ttrain-auc:0.933701\teval-auc:0.897811\n",
      "[15600]\ttrain-auc:0.933824\teval-auc:0.897807\n",
      "[15700]\ttrain-auc:0.933952\teval-auc:0.897833\n",
      "[15800]\ttrain-auc:0.934072\teval-auc:0.897817\n",
      "[15900]\ttrain-auc:0.934193\teval-auc:0.897843\n",
      "[16000]\ttrain-auc:0.934306\teval-auc:0.89785\n",
      "[16100]\ttrain-auc:0.934414\teval-auc:0.897853\n",
      "[16200]\ttrain-auc:0.934549\teval-auc:0.89785\n",
      "Stopping. Best iteration:\n",
      "[15973]\ttrain-auc:0.934276\teval-auc:0.897871\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param = {'objective':'binary:logistic', 'eval_metric':['auc'], 'eta':0.015, 'max_depth':2, 'colsample_bytree':0.75,\n",
    "         'colsample_bylevel':0.75, 'colsample_bynode':0.75, 'subsample':0.8, 'n_estimators':1500, 'tree_method': 'gpu_hist'\n",
    "        }\n",
    "evallist = [ (dtrain, 'train'), (dval, 'eval')]\n",
    "num_round = 500000\n",
    "nfold = 5\n",
    "bst1 = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds = 300, verbose_eval = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2i1 = pipeline.predict_proba(X_train_s2)[:, 1]  #stage 2 input 1\n",
    "s2i2 = bst1.predict(xgb.DMatrix(X_train_s2), ntree_limit=bst1.best_ntree_limit) #stage 2 input 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I try NN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, ELU, Input, Concatenate\n",
    "from keras.models import Sequential, Model\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Nadam\n",
    "\n",
    "num_cores = 4\n",
    "config = tf.ConfigProto(intra_op_parallelism_threads=num_cores,\n",
    "                        inter_op_parallelism_threads=num_cores, \n",
    "                        allow_soft_placement=True,\n",
    "                        device_count = {'CPU' : 1,\n",
    "                                        'GPU' : 1}\n",
    "                       )\n",
    "\n",
    "session = tf.Session(config=config)\n",
    "K.set_session(session)\n",
    "\n",
    "opt = Nadam(lr = 0.002)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = Input((200,))\n",
    "model_a = Sequential()\n",
    "bonus_1 = Dense(200, input_dim = 200, activation = 'tanh') #Ie not trainable part of the final model.\n",
    "bonus_2 = Dense(100, input_dim = 200, activation = 'tanh') #Ie not trainable part of the final model.\n",
    "#model_a.add(bonus_1)\n",
    "\n",
    "model_a.add(bonus_2)\n",
    "model_a.add(Dense(1, input_shape = (200,), activation = 'sigmoid'))\n",
    "output_a = model_a(input_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding stuff to the above breaks it for some reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 153000 samples, validate on 17000 samples\n",
      "Epoch 1/250\n",
      "10/10 [==============================] - 3s 315ms/step - loss: 0.3884 - binary_accuracy: 0.8546 - val_loss: 0.3340 - val_binary_accuracy: 0.8993\n",
      "Epoch 2/250\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.3235 - binary_accuracy: 0.9003 - val_loss: 0.3194 - val_binary_accuracy: 0.8993\n",
      "Epoch 3/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.3102 - binary_accuracy: 0.9004 - val_loss: 0.3099 - val_binary_accuracy: 0.8992\n",
      "Epoch 4/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.3019 - binary_accuracy: 0.9005 - val_loss: 0.3057 - val_binary_accuracy: 0.8993\n",
      "Epoch 5/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2970 - binary_accuracy: 0.9006 - val_loss: 0.3019 - val_binary_accuracy: 0.8995\n",
      "Epoch 6/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2917 - binary_accuracy: 0.9010 - val_loss: 0.2981 - val_binary_accuracy: 0.8995\n",
      "Epoch 7/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2878 - binary_accuracy: 0.9014 - val_loss: 0.2960 - val_binary_accuracy: 0.8997\n",
      "Epoch 8/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2847 - binary_accuracy: 0.9017 - val_loss: 0.2936 - val_binary_accuracy: 0.8999\n",
      "Epoch 9/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2819 - binary_accuracy: 0.9021 - val_loss: 0.2915 - val_binary_accuracy: 0.9001\n",
      "Epoch 10/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2794 - binary_accuracy: 0.9025 - val_loss: 0.2901 - val_binary_accuracy: 0.8999\n",
      "Epoch 11/250\n",
      "10/10 [==============================] - 2s 195ms/step - loss: 0.2774 - binary_accuracy: 0.9029 - val_loss: 0.2883 - val_binary_accuracy: 0.9000\n",
      "Epoch 12/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2753 - binary_accuracy: 0.9032 - val_loss: 0.2873 - val_binary_accuracy: 0.9001\n",
      "Epoch 13/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2736 - binary_accuracy: 0.9036 - val_loss: 0.2862 - val_binary_accuracy: 0.9001\n",
      "Epoch 14/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2719 - binary_accuracy: 0.9039 - val_loss: 0.2854 - val_binary_accuracy: 0.9004\n",
      "Epoch 15/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2704 - binary_accuracy: 0.9042 - val_loss: 0.2843 - val_binary_accuracy: 0.9006\n",
      "Epoch 16/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2690 - binary_accuracy: 0.9045 - val_loss: 0.2837 - val_binary_accuracy: 0.9008\n",
      "Epoch 17/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2677 - binary_accuracy: 0.9047 - val_loss: 0.2828 - val_binary_accuracy: 0.9011\n",
      "Epoch 18/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2664 - binary_accuracy: 0.9050 - val_loss: 0.2822 - val_binary_accuracy: 0.9013\n",
      "Epoch 19/250\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.2653 - binary_accuracy: 0.9052 - val_loss: 0.2816 - val_binary_accuracy: 0.9014\n",
      "Epoch 20/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2642 - binary_accuracy: 0.9056 - val_loss: 0.2809 - val_binary_accuracy: 0.9015\n",
      "Epoch 21/250\n",
      "10/10 [==============================] - 2s 196ms/step - loss: 0.2632 - binary_accuracy: 0.9058 - val_loss: 0.2804 - val_binary_accuracy: 0.9017\n",
      "Epoch 22/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2622 - binary_accuracy: 0.9061 - val_loss: 0.2799 - val_binary_accuracy: 0.9018\n",
      "Epoch 23/250\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.2613 - binary_accuracy: 0.9063 - val_loss: 0.2795 - val_binary_accuracy: 0.9019\n",
      "Epoch 24/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2604 - binary_accuracy: 0.9065 - val_loss: 0.2790 - val_binary_accuracy: 0.9022\n",
      "Epoch 25/250\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.2596 - binary_accuracy: 0.9067 - val_loss: 0.2787 - val_binary_accuracy: 0.9022\n",
      "Epoch 26/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2592 - binary_accuracy: 0.9068 - val_loss: 0.2888 - val_binary_accuracy: 0.9015\n",
      "Epoch 27/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2589 - binary_accuracy: 0.9070 - val_loss: 0.2757 - val_binary_accuracy: 0.9022\n",
      "Epoch 28/250\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.2564 - binary_accuracy: 0.9074 - val_loss: 0.2778 - val_binary_accuracy: 0.9023\n",
      "Epoch 29/250\n",
      "10/10 [==============================] - 2s 199ms/step - loss: 0.2568 - binary_accuracy: 0.9073 - val_loss: 0.2776 - val_binary_accuracy: 0.9022\n",
      "Epoch 30/250\n",
      "10/10 [==============================] - 2s 198ms/step - loss: 0.2561 - binary_accuracy: 0.9075 - val_loss: 0.2770 - val_binary_accuracy: 0.9023\n",
      "Epoch 31/250\n",
      "10/10 [==============================] - 2s 197ms/step - loss: 0.2553 - binary_accuracy: 0.9077 - val_loss: 0.2767 - val_binary_accuracy: 0.9024\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "model_a.compile(optimizer = opt,\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['binary_accuracy']\n",
    ")\n",
    "\n",
    "stop = EarlyStopping(patience = 4, verbose =1, restore_best_weights = True)\n",
    "model_a.fit(X_train_s1, y_train_s1,\n",
    "    steps_per_epoch=10,\n",
    "    validation_split = 0.1,\n",
    "    validation_steps = 2,\n",
    "    callbacks = [stop],\n",
    "    epochs=250)\n",
    "\n",
    "bonus_1.trainable = False\n",
    "bonus_2.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result above should be below 0.27, otherwise regression converged to a wrong minimum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 200)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_1 (Sequential)       (None, 1)            20201       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3)            0           sequential_1[1][0]               \n",
      "                                                                 input_2[0][0]                    \n",
      "                                                                 input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            4           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,205\n",
      "Trainable params: 105\n",
      "Non-trainable params: 20,100\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_aux1 = Input((1,))\n",
    "input_aux2 = Input((1,))\n",
    "input_b = Concatenate()([output_a, input_aux1, input_aux2])\n",
    "model_b = Sequential()\n",
    "#model_b.add(Dense(20, input_dim = 12))\n",
    "#model_b.add(ELU())\n",
    "model_b.add(Dense(1))\n",
    "output_b=model_b(input_b)\n",
    "model = Model(inputs=[input_a, input_aux1, input_aux2], outputs=output_b)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 27000 samples, validate on 3000 samples\n",
      "Epoch 1/500\n",
      "10/10 [==============================] - 0s 50ms/step - loss: 1.2782 - binary_accuracy: 0.8923 - val_loss: 1.1064 - val_binary_accuracy: 0.8920\n",
      "Epoch 2/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 1.0124 - binary_accuracy: 0.8953 - val_loss: 0.9360 - val_binary_accuracy: 0.8917\n",
      "Epoch 3/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.8162 - binary_accuracy: 0.8917 - val_loss: 0.6209 - val_binary_accuracy: 0.8780\n",
      "Epoch 4/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.5352 - binary_accuracy: 0.8320 - val_loss: 0.4784 - val_binary_accuracy: 0.8323\n",
      "Epoch 5/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4740 - binary_accuracy: 0.8285 - val_loss: 0.4502 - val_binary_accuracy: 0.8580\n",
      "Epoch 6/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4543 - binary_accuracy: 0.8388 - val_loss: 0.4697 - val_binary_accuracy: 0.8013\n",
      "Epoch 7/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4530 - binary_accuracy: 0.8141 - val_loss: 0.4260 - val_binary_accuracy: 0.8333\n",
      "Epoch 8/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.4065 - binary_accuracy: 0.8596 - val_loss: 0.4028 - val_binary_accuracy: 0.8673\n",
      "Epoch 9/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3901 - binary_accuracy: 0.8756 - val_loss: 0.3941 - val_binary_accuracy: 0.8697\n",
      "Epoch 10/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3801 - binary_accuracy: 0.8798 - val_loss: 0.3881 - val_binary_accuracy: 0.8733\n",
      "Epoch 11/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3715 - binary_accuracy: 0.8830 - val_loss: 0.3779 - val_binary_accuracy: 0.8747\n",
      "Epoch 12/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3624 - binary_accuracy: 0.8846 - val_loss: 0.3689 - val_binary_accuracy: 0.8757\n",
      "Epoch 13/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3519 - binary_accuracy: 0.8856 - val_loss: 0.3602 - val_binary_accuracy: 0.8790\n",
      "Epoch 14/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3448 - binary_accuracy: 0.8875 - val_loss: 0.3533 - val_binary_accuracy: 0.8810\n",
      "Epoch 15/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3387 - binary_accuracy: 0.8888 - val_loss: 0.3455 - val_binary_accuracy: 0.8827\n",
      "Epoch 16/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3328 - binary_accuracy: 0.8897 - val_loss: 0.3398 - val_binary_accuracy: 0.8837\n",
      "Epoch 17/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3273 - binary_accuracy: 0.8904 - val_loss: 0.3317 - val_binary_accuracy: 0.8837\n",
      "Epoch 18/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.3209 - binary_accuracy: 0.8909 - val_loss: 0.3229 - val_binary_accuracy: 0.8833\n",
      "Epoch 19/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3151 - binary_accuracy: 0.8916 - val_loss: 0.3188 - val_binary_accuracy: 0.8853\n",
      "Epoch 20/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3075 - binary_accuracy: 0.8922 - val_loss: 0.3143 - val_binary_accuracy: 0.8850\n",
      "Epoch 21/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.3006 - binary_accuracy: 0.8931 - val_loss: 0.3073 - val_binary_accuracy: 0.8860\n",
      "Epoch 22/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2961 - binary_accuracy: 0.8947 - val_loss: 0.3030 - val_binary_accuracy: 0.8890\n",
      "Epoch 23/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2907 - binary_accuracy: 0.8965 - val_loss: 0.2996 - val_binary_accuracy: 0.8907\n",
      "Epoch 24/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2864 - binary_accuracy: 0.8976 - val_loss: 0.2965 - val_binary_accuracy: 0.8913\n",
      "Epoch 25/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2825 - binary_accuracy: 0.8988 - val_loss: 0.2939 - val_binary_accuracy: 0.8910\n",
      "Epoch 26/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2795 - binary_accuracy: 0.8998 - val_loss: 0.2916 - val_binary_accuracy: 0.8920\n",
      "Epoch 27/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2770 - binary_accuracy: 0.9007 - val_loss: 0.2895 - val_binary_accuracy: 0.8937\n",
      "Epoch 28/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2747 - binary_accuracy: 0.9016 - val_loss: 0.2876 - val_binary_accuracy: 0.8947\n",
      "Epoch 29/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2726 - binary_accuracy: 0.9022 - val_loss: 0.2858 - val_binary_accuracy: 0.8943\n",
      "Epoch 30/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2706 - binary_accuracy: 0.9028 - val_loss: 0.2842 - val_binary_accuracy: 0.8950\n",
      "Epoch 31/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2688 - binary_accuracy: 0.9034 - val_loss: 0.2826 - val_binary_accuracy: 0.8950\n",
      "Epoch 32/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2671 - binary_accuracy: 0.9039 - val_loss: 0.2811 - val_binary_accuracy: 0.8953\n",
      "Epoch 33/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2648 - binary_accuracy: 0.9045 - val_loss: 0.2794 - val_binary_accuracy: 0.8950\n",
      "Epoch 34/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2626 - binary_accuracy: 0.9050 - val_loss: 0.2780 - val_binary_accuracy: 0.8947\n",
      "Epoch 35/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2609 - binary_accuracy: 0.9052 - val_loss: 0.2767 - val_binary_accuracy: 0.8953\n",
      "Epoch 36/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2593 - binary_accuracy: 0.9056 - val_loss: 0.2755 - val_binary_accuracy: 0.8960\n",
      "Epoch 37/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2579 - binary_accuracy: 0.9060 - val_loss: 0.2744 - val_binary_accuracy: 0.8960\n",
      "Epoch 38/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2566 - binary_accuracy: 0.9064 - val_loss: 0.2732 - val_binary_accuracy: 0.8967\n",
      "Epoch 39/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2553 - binary_accuracy: 0.9067 - val_loss: 0.2722 - val_binary_accuracy: 0.8967\n",
      "Epoch 40/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2541 - binary_accuracy: 0.9069 - val_loss: 0.2711 - val_binary_accuracy: 0.8967\n",
      "Epoch 41/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2529 - binary_accuracy: 0.9069 - val_loss: 0.2701 - val_binary_accuracy: 0.8967\n",
      "Epoch 42/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2518 - binary_accuracy: 0.9069 - val_loss: 0.2691 - val_binary_accuracy: 0.8967\n",
      "Epoch 43/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2507 - binary_accuracy: 0.9071 - val_loss: 0.2682 - val_binary_accuracy: 0.8967\n",
      "Epoch 44/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2496 - binary_accuracy: 0.9074 - val_loss: 0.2673 - val_binary_accuracy: 0.8977\n",
      "Epoch 45/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2485 - binary_accuracy: 0.9074 - val_loss: 0.2664 - val_binary_accuracy: 0.8980\n",
      "Epoch 46/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2475 - binary_accuracy: 0.9077 - val_loss: 0.2655 - val_binary_accuracy: 0.8987\n",
      "Epoch 47/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2466 - binary_accuracy: 0.9079 - val_loss: 0.2647 - val_binary_accuracy: 0.8987\n",
      "Epoch 48/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2456 - binary_accuracy: 0.9080 - val_loss: 0.2639 - val_binary_accuracy: 0.8993\n",
      "Epoch 49/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2447 - binary_accuracy: 0.9081 - val_loss: 0.2631 - val_binary_accuracy: 0.9000\n",
      "Epoch 50/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2438 - binary_accuracy: 0.9082 - val_loss: 0.2623 - val_binary_accuracy: 0.9000\n",
      "Epoch 51/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2429 - binary_accuracy: 0.9082 - val_loss: 0.2616 - val_binary_accuracy: 0.8993\n",
      "Epoch 52/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2421 - binary_accuracy: 0.9083 - val_loss: 0.2608 - val_binary_accuracy: 0.9000\n",
      "Epoch 53/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2412 - binary_accuracy: 0.9084 - val_loss: 0.2601 - val_binary_accuracy: 0.9000\n",
      "Epoch 54/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2404 - binary_accuracy: 0.9086 - val_loss: 0.2594 - val_binary_accuracy: 0.9003\n",
      "Epoch 55/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2396 - binary_accuracy: 0.9088 - val_loss: 0.2587 - val_binary_accuracy: 0.9000\n",
      "Epoch 56/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2388 - binary_accuracy: 0.9090 - val_loss: 0.2580 - val_binary_accuracy: 0.9003\n",
      "Epoch 57/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2381 - binary_accuracy: 0.9091 - val_loss: 0.2574 - val_binary_accuracy: 0.9003\n",
      "Epoch 58/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2373 - binary_accuracy: 0.9093 - val_loss: 0.2567 - val_binary_accuracy: 0.9000\n",
      "Epoch 59/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2366 - binary_accuracy: 0.9096 - val_loss: 0.2561 - val_binary_accuracy: 0.9003\n",
      "Epoch 60/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2359 - binary_accuracy: 0.9099 - val_loss: 0.2555 - val_binary_accuracy: 0.9003\n",
      "Epoch 61/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2352 - binary_accuracy: 0.9101 - val_loss: 0.2549 - val_binary_accuracy: 0.9007\n",
      "Epoch 62/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2345 - binary_accuracy: 0.9103 - val_loss: 0.2543 - val_binary_accuracy: 0.9007\n",
      "Epoch 63/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2338 - binary_accuracy: 0.9105 - val_loss: 0.2537 - val_binary_accuracy: 0.9013\n",
      "Epoch 64/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2332 - binary_accuracy: 0.9105 - val_loss: 0.2531 - val_binary_accuracy: 0.9020\n",
      "Epoch 65/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2326 - binary_accuracy: 0.9106 - val_loss: 0.2526 - val_binary_accuracy: 0.9023\n",
      "Epoch 66/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2319 - binary_accuracy: 0.9108 - val_loss: 0.2521 - val_binary_accuracy: 0.9023\n",
      "Epoch 67/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2313 - binary_accuracy: 0.9111 - val_loss: 0.2515 - val_binary_accuracy: 0.9023\n",
      "Epoch 68/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2307 - binary_accuracy: 0.9113 - val_loss: 0.2510 - val_binary_accuracy: 0.9027\n",
      "Epoch 69/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2302 - binary_accuracy: 0.9115 - val_loss: 0.2505 - val_binary_accuracy: 0.9030\n",
      "Epoch 70/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2296 - binary_accuracy: 0.9117 - val_loss: 0.2500 - val_binary_accuracy: 0.9030\n",
      "Epoch 71/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2290 - binary_accuracy: 0.9119 - val_loss: 0.2495 - val_binary_accuracy: 0.9037\n",
      "Epoch 72/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2285 - binary_accuracy: 0.9121 - val_loss: 0.2491 - val_binary_accuracy: 0.9037\n",
      "Epoch 73/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2279 - binary_accuracy: 0.9120 - val_loss: 0.2486 - val_binary_accuracy: 0.9047\n",
      "Epoch 74/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2274 - binary_accuracy: 0.9121 - val_loss: 0.2482 - val_binary_accuracy: 0.9047\n",
      "Epoch 75/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2269 - binary_accuracy: 0.9123 - val_loss: 0.2477 - val_binary_accuracy: 0.9047\n",
      "Epoch 76/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2264 - binary_accuracy: 0.9125 - val_loss: 0.2473 - val_binary_accuracy: 0.9047\n",
      "Epoch 77/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2259 - binary_accuracy: 0.9129 - val_loss: 0.2469 - val_binary_accuracy: 0.9050\n",
      "Epoch 78/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2254 - binary_accuracy: 0.9132 - val_loss: 0.2465 - val_binary_accuracy: 0.9050\n",
      "Epoch 79/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2250 - binary_accuracy: 0.9134 - val_loss: 0.2461 - val_binary_accuracy: 0.9057\n",
      "Epoch 80/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2245 - binary_accuracy: 0.9136 - val_loss: 0.2457 - val_binary_accuracy: 0.9060\n",
      "Epoch 81/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2240 - binary_accuracy: 0.9139 - val_loss: 0.2454 - val_binary_accuracy: 0.9060\n",
      "Epoch 82/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2236 - binary_accuracy: 0.9139 - val_loss: 0.2450 - val_binary_accuracy: 0.9067\n",
      "Epoch 83/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2232 - binary_accuracy: 0.9142 - val_loss: 0.2447 - val_binary_accuracy: 0.9067\n",
      "Epoch 84/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2228 - binary_accuracy: 0.9144 - val_loss: 0.2443 - val_binary_accuracy: 0.9070\n",
      "Epoch 85/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2223 - binary_accuracy: 0.9145 - val_loss: 0.2441 - val_binary_accuracy: 0.9070\n",
      "Epoch 86/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2220 - binary_accuracy: 0.9148 - val_loss: 0.2438 - val_binary_accuracy: 0.9083\n",
      "Epoch 87/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2216 - binary_accuracy: 0.9150 - val_loss: 0.2435 - val_binary_accuracy: 0.9090\n",
      "Epoch 88/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2212 - binary_accuracy: 0.9152 - val_loss: 0.2434 - val_binary_accuracy: 0.9093\n",
      "Epoch 89/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2208 - binary_accuracy: 0.9155 - val_loss: 0.2434 - val_binary_accuracy: 0.9093\n",
      "Epoch 90/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2205 - binary_accuracy: 0.9157 - val_loss: 0.2463 - val_binary_accuracy: 0.9097\n",
      "Epoch 91/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2202 - binary_accuracy: 0.9159 - val_loss: 0.2461 - val_binary_accuracy: 0.9097\n",
      "Epoch 92/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2200 - binary_accuracy: 0.9159 - val_loss: 0.2458 - val_binary_accuracy: 0.9103\n",
      "Epoch 93/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2197 - binary_accuracy: 0.9159 - val_loss: 0.2455 - val_binary_accuracy: 0.9103\n",
      "Epoch 94/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2195 - binary_accuracy: 0.9159 - val_loss: 0.2452 - val_binary_accuracy: 0.9107\n",
      "Epoch 95/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2192 - binary_accuracy: 0.9159 - val_loss: 0.2450 - val_binary_accuracy: 0.9110\n",
      "Epoch 96/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2190 - binary_accuracy: 0.9159 - val_loss: 0.2447 - val_binary_accuracy: 0.9110\n",
      "Epoch 97/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2188 - binary_accuracy: 0.9160 - val_loss: 0.2444 - val_binary_accuracy: 0.9117\n",
      "Epoch 98/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2186 - binary_accuracy: 0.9162 - val_loss: 0.2442 - val_binary_accuracy: 0.9113\n",
      "Epoch 99/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2183 - binary_accuracy: 0.9164 - val_loss: 0.2439 - val_binary_accuracy: 0.9110\n",
      "Epoch 100/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2181 - binary_accuracy: 0.9164 - val_loss: 0.2437 - val_binary_accuracy: 0.9113\n",
      "Epoch 101/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2179 - binary_accuracy: 0.9164 - val_loss: 0.2434 - val_binary_accuracy: 0.9113\n",
      "Epoch 102/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2177 - binary_accuracy: 0.9166 - val_loss: 0.2432 - val_binary_accuracy: 0.9117\n",
      "Epoch 103/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2175 - binary_accuracy: 0.9166 - val_loss: 0.2429 - val_binary_accuracy: 0.9120\n",
      "Epoch 104/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2173 - binary_accuracy: 0.9168 - val_loss: 0.2427 - val_binary_accuracy: 0.9127\n",
      "Epoch 105/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2170 - binary_accuracy: 0.9169 - val_loss: 0.2425 - val_binary_accuracy: 0.9127\n",
      "Epoch 106/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2168 - binary_accuracy: 0.9171 - val_loss: 0.2422 - val_binary_accuracy: 0.9127\n",
      "Epoch 107/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2166 - binary_accuracy: 0.9173 - val_loss: 0.2420 - val_binary_accuracy: 0.9133\n",
      "Epoch 108/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2164 - binary_accuracy: 0.9175 - val_loss: 0.2418 - val_binary_accuracy: 0.9133\n",
      "Epoch 109/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2162 - binary_accuracy: 0.9176 - val_loss: 0.2415 - val_binary_accuracy: 0.9130\n",
      "Epoch 110/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2160 - binary_accuracy: 0.9176 - val_loss: 0.2413 - val_binary_accuracy: 0.9130\n",
      "Epoch 111/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2158 - binary_accuracy: 0.9177 - val_loss: 0.2411 - val_binary_accuracy: 0.9133\n",
      "Epoch 112/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2156 - binary_accuracy: 0.9178 - val_loss: 0.2409 - val_binary_accuracy: 0.9133\n",
      "Epoch 113/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2154 - binary_accuracy: 0.9181 - val_loss: 0.2406 - val_binary_accuracy: 0.9133\n",
      "Epoch 114/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2152 - binary_accuracy: 0.9182 - val_loss: 0.2404 - val_binary_accuracy: 0.9133\n",
      "Epoch 115/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2150 - binary_accuracy: 0.9180 - val_loss: 0.2402 - val_binary_accuracy: 0.9133\n",
      "Epoch 116/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2148 - binary_accuracy: 0.9182 - val_loss: 0.2400 - val_binary_accuracy: 0.9133\n",
      "Epoch 117/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2146 - binary_accuracy: 0.9183 - val_loss: 0.2398 - val_binary_accuracy: 0.9137\n",
      "Epoch 118/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2144 - binary_accuracy: 0.9183 - val_loss: 0.2395 - val_binary_accuracy: 0.9133\n",
      "Epoch 119/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2142 - binary_accuracy: 0.9183 - val_loss: 0.2393 - val_binary_accuracy: 0.9137\n",
      "Epoch 120/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2140 - binary_accuracy: 0.9185 - val_loss: 0.2391 - val_binary_accuracy: 0.9137\n",
      "Epoch 121/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2138 - binary_accuracy: 0.9186 - val_loss: 0.2389 - val_binary_accuracy: 0.9140\n",
      "Epoch 122/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2136 - binary_accuracy: 0.9187 - val_loss: 0.2387 - val_binary_accuracy: 0.9143\n",
      "Epoch 123/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2134 - binary_accuracy: 0.9188 - val_loss: 0.2385 - val_binary_accuracy: 0.9143\n",
      "Epoch 124/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2132 - binary_accuracy: 0.9189 - val_loss: 0.2383 - val_binary_accuracy: 0.9143\n",
      "Epoch 125/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2130 - binary_accuracy: 0.9190 - val_loss: 0.2381 - val_binary_accuracy: 0.9143\n",
      "Epoch 126/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2128 - binary_accuracy: 0.9191 - val_loss: 0.2379 - val_binary_accuracy: 0.9140\n",
      "Epoch 127/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2126 - binary_accuracy: 0.9193 - val_loss: 0.2377 - val_binary_accuracy: 0.9140\n",
      "Epoch 128/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2124 - binary_accuracy: 0.9194 - val_loss: 0.2375 - val_binary_accuracy: 0.9143\n",
      "Epoch 129/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2122 - binary_accuracy: 0.9195 - val_loss: 0.2373 - val_binary_accuracy: 0.9147\n",
      "Epoch 130/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2120 - binary_accuracy: 0.9196 - val_loss: 0.2371 - val_binary_accuracy: 0.9147\n",
      "Epoch 131/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2119 - binary_accuracy: 0.9197 - val_loss: 0.2369 - val_binary_accuracy: 0.9147\n",
      "Epoch 132/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2117 - binary_accuracy: 0.9198 - val_loss: 0.2367 - val_binary_accuracy: 0.9147\n",
      "Epoch 133/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2115 - binary_accuracy: 0.9200 - val_loss: 0.2365 - val_binary_accuracy: 0.9147\n",
      "Epoch 134/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2113 - binary_accuracy: 0.9202 - val_loss: 0.2364 - val_binary_accuracy: 0.9143\n",
      "Epoch 135/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2112 - binary_accuracy: 0.9203 - val_loss: 0.2362 - val_binary_accuracy: 0.9140\n",
      "Epoch 136/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2110 - binary_accuracy: 0.9205 - val_loss: 0.2360 - val_binary_accuracy: 0.9147\n",
      "Epoch 137/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2108 - binary_accuracy: 0.9206 - val_loss: 0.2358 - val_binary_accuracy: 0.9147\n",
      "Epoch 138/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2107 - binary_accuracy: 0.9206 - val_loss: 0.2357 - val_binary_accuracy: 0.9153\n",
      "Epoch 139/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2105 - binary_accuracy: 0.9208 - val_loss: 0.2355 - val_binary_accuracy: 0.9157\n",
      "Epoch 140/500\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2103 - binary_accuracy: 0.9210 - val_loss: 0.2353 - val_binary_accuracy: 0.9160\n",
      "Epoch 141/500\n",
      "10/10 [==============================] - 0s 24ms/step - loss: 0.2102 - binary_accuracy: 0.9212 - val_loss: 0.2352 - val_binary_accuracy: 0.9157\n",
      "Epoch 142/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2100 - binary_accuracy: 0.9212 - val_loss: 0.2350 - val_binary_accuracy: 0.9157\n",
      "Epoch 143/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2099 - binary_accuracy: 0.9213 - val_loss: 0.2348 - val_binary_accuracy: 0.9163\n",
      "Epoch 144/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2097 - binary_accuracy: 0.9214 - val_loss: 0.2347 - val_binary_accuracy: 0.9160\n",
      "Epoch 145/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2096 - binary_accuracy: 0.9214 - val_loss: 0.2345 - val_binary_accuracy: 0.9160\n",
      "Epoch 146/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2095 - binary_accuracy: 0.9215 - val_loss: 0.2344 - val_binary_accuracy: 0.9160\n",
      "Epoch 147/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2093 - binary_accuracy: 0.9215 - val_loss: 0.2342 - val_binary_accuracy: 0.9157\n",
      "Epoch 148/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2092 - binary_accuracy: 0.9216 - val_loss: 0.2341 - val_binary_accuracy: 0.9157\n",
      "Epoch 149/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2091 - binary_accuracy: 0.9218 - val_loss: 0.2339 - val_binary_accuracy: 0.9160\n",
      "Epoch 150/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2089 - binary_accuracy: 0.9220 - val_loss: 0.2338 - val_binary_accuracy: 0.9163\n",
      "Epoch 151/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2088 - binary_accuracy: 0.9220 - val_loss: 0.2336 - val_binary_accuracy: 0.9163\n",
      "Epoch 152/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2087 - binary_accuracy: 0.9221 - val_loss: 0.2335 - val_binary_accuracy: 0.9167\n",
      "Epoch 153/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2086 - binary_accuracy: 0.9221 - val_loss: 0.2333 - val_binary_accuracy: 0.9170\n",
      "Epoch 154/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2084 - binary_accuracy: 0.9222 - val_loss: 0.2332 - val_binary_accuracy: 0.9170\n",
      "Epoch 155/500\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2083 - binary_accuracy: 0.9222 - val_loss: 0.2331 - val_binary_accuracy: 0.9173\n",
      "Epoch 156/500\n",
      "10/10 [==============================] - 0s 22ms/step - loss: 0.2082 - binary_accuracy: 0.9222 - val_loss: 0.2329 - val_binary_accuracy: 0.9173\n",
      "Epoch 157/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2081 - binary_accuracy: 0.9223 - val_loss: 0.2328 - val_binary_accuracy: 0.9173\n",
      "Epoch 158/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2080 - binary_accuracy: 0.9223 - val_loss: 0.2327 - val_binary_accuracy: 0.9173\n",
      "Epoch 159/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2079 - binary_accuracy: 0.9224 - val_loss: 0.2325 - val_binary_accuracy: 0.9173\n",
      "Epoch 160/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2078 - binary_accuracy: 0.9224 - val_loss: 0.2324 - val_binary_accuracy: 0.9177\n",
      "Epoch 161/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2077 - binary_accuracy: 0.9225 - val_loss: 0.2323 - val_binary_accuracy: 0.9177\n",
      "Epoch 162/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2076 - binary_accuracy: 0.9225 - val_loss: 0.2322 - val_binary_accuracy: 0.9177\n",
      "Epoch 163/500\n",
      "10/10 [==============================] - 0s 23ms/step - loss: 0.2075 - binary_accuracy: 0.9227 - val_loss: 0.2321 - val_binary_accuracy: 0.9177\n",
      "Epoch 164/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2074 - binary_accuracy: 0.9228 - val_loss: 0.2320 - val_binary_accuracy: 0.9180\n",
      "Epoch 165/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2073 - binary_accuracy: 0.9229 - val_loss: 0.2318 - val_binary_accuracy: 0.9180\n",
      "Epoch 166/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2072 - binary_accuracy: 0.9229 - val_loss: 0.2317 - val_binary_accuracy: 0.9183\n",
      "Epoch 167/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2071 - binary_accuracy: 0.9228 - val_loss: 0.2316 - val_binary_accuracy: 0.9187\n",
      "Epoch 168/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2070 - binary_accuracy: 0.9228 - val_loss: 0.2315 - val_binary_accuracy: 0.9187\n",
      "Epoch 169/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2069 - binary_accuracy: 0.9228 - val_loss: 0.2314 - val_binary_accuracy: 0.9187\n",
      "Epoch 170/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2068 - binary_accuracy: 0.9228 - val_loss: 0.2313 - val_binary_accuracy: 0.9187\n",
      "Epoch 171/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2067 - binary_accuracy: 0.9228 - val_loss: 0.2312 - val_binary_accuracy: 0.9183\n",
      "Epoch 172/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2066 - binary_accuracy: 0.9228 - val_loss: 0.2312 - val_binary_accuracy: 0.9183\n",
      "Epoch 173/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2065 - binary_accuracy: 0.9229 - val_loss: 0.2311 - val_binary_accuracy: 0.9183\n",
      "Epoch 174/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2065 - binary_accuracy: 0.9229 - val_loss: 0.2310 - val_binary_accuracy: 0.9183\n",
      "Epoch 175/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2064 - binary_accuracy: 0.9230 - val_loss: 0.2309 - val_binary_accuracy: 0.9183\n",
      "Epoch 176/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2063 - binary_accuracy: 0.9230 - val_loss: 0.2308 - val_binary_accuracy: 0.9183\n",
      "Epoch 177/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2062 - binary_accuracy: 0.9230 - val_loss: 0.2307 - val_binary_accuracy: 0.9183\n",
      "Epoch 178/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2062 - binary_accuracy: 0.9230 - val_loss: 0.2307 - val_binary_accuracy: 0.9183\n",
      "Epoch 179/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2061 - binary_accuracy: 0.9231 - val_loss: 0.2306 - val_binary_accuracy: 0.9190\n",
      "Epoch 180/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2060 - binary_accuracy: 0.9230 - val_loss: 0.2305 - val_binary_accuracy: 0.9183\n",
      "Epoch 181/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2060 - binary_accuracy: 0.9230 - val_loss: 0.2304 - val_binary_accuracy: 0.9183\n",
      "Epoch 182/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2059 - binary_accuracy: 0.9231 - val_loss: 0.2304 - val_binary_accuracy: 0.9183\n",
      "Epoch 183/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2058 - binary_accuracy: 0.9231 - val_loss: 0.2303 - val_binary_accuracy: 0.9187\n",
      "Epoch 184/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2058 - binary_accuracy: 0.9232 - val_loss: 0.2302 - val_binary_accuracy: 0.9187\n",
      "Epoch 185/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2057 - binary_accuracy: 0.9233 - val_loss: 0.2302 - val_binary_accuracy: 0.9187\n",
      "Epoch 186/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2057 - binary_accuracy: 0.9233 - val_loss: 0.2301 - val_binary_accuracy: 0.9187\n",
      "Epoch 187/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2056 - binary_accuracy: 0.9233 - val_loss: 0.2301 - val_binary_accuracy: 0.9190\n",
      "Epoch 188/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2056 - binary_accuracy: 0.9235 - val_loss: 0.2300 - val_binary_accuracy: 0.9190\n",
      "Epoch 189/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2055 - binary_accuracy: 0.9236 - val_loss: 0.2299 - val_binary_accuracy: 0.9193\n",
      "Epoch 190/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2055 - binary_accuracy: 0.9236 - val_loss: 0.2299 - val_binary_accuracy: 0.9193\n",
      "Epoch 191/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2054 - binary_accuracy: 0.9235 - val_loss: 0.2298 - val_binary_accuracy: 0.9190\n",
      "Epoch 192/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2054 - binary_accuracy: 0.9234 - val_loss: 0.2298 - val_binary_accuracy: 0.9193\n",
      "Epoch 193/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2054 - binary_accuracy: 0.9234 - val_loss: 0.2297 - val_binary_accuracy: 0.9193\n",
      "Epoch 194/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2053 - binary_accuracy: 0.9234 - val_loss: 0.2297 - val_binary_accuracy: 0.9193\n",
      "Epoch 195/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2053 - binary_accuracy: 0.9234 - val_loss: 0.2296 - val_binary_accuracy: 0.9193\n",
      "Epoch 196/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2053 - binary_accuracy: 0.9234 - val_loss: 0.2296 - val_binary_accuracy: 0.9193\n",
      "Epoch 197/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2052 - binary_accuracy: 0.9233 - val_loss: 0.2296 - val_binary_accuracy: 0.9193\n",
      "Epoch 198/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2052 - binary_accuracy: 0.9233 - val_loss: 0.2295 - val_binary_accuracy: 0.9193\n",
      "Epoch 199/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2052 - binary_accuracy: 0.9233 - val_loss: 0.2295 - val_binary_accuracy: 0.9197\n",
      "Epoch 200/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2051 - binary_accuracy: 0.9233 - val_loss: 0.2294 - val_binary_accuracy: 0.9197\n",
      "Epoch 201/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2051 - binary_accuracy: 0.9233 - val_loss: 0.2294 - val_binary_accuracy: 0.9197\n",
      "Epoch 202/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2051 - binary_accuracy: 0.9233 - val_loss: 0.2294 - val_binary_accuracy: 0.9197\n",
      "Epoch 203/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2051 - binary_accuracy: 0.9235 - val_loss: 0.2293 - val_binary_accuracy: 0.9197\n",
      "Epoch 204/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2051 - binary_accuracy: 0.9235 - val_loss: 0.2293 - val_binary_accuracy: 0.9197\n",
      "Epoch 205/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2050 - binary_accuracy: 0.9235 - val_loss: 0.2292 - val_binary_accuracy: 0.9197\n",
      "Epoch 206/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2050 - binary_accuracy: 0.9235 - val_loss: 0.2292 - val_binary_accuracy: 0.9197\n",
      "Epoch 207/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2050 - binary_accuracy: 0.9235 - val_loss: 0.2292 - val_binary_accuracy: 0.9197\n",
      "Epoch 208/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2050 - binary_accuracy: 0.9236 - val_loss: 0.2291 - val_binary_accuracy: 0.9197\n",
      "Epoch 209/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2050 - binary_accuracy: 0.9236 - val_loss: 0.2291 - val_binary_accuracy: 0.9197\n",
      "Epoch 210/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2291 - val_binary_accuracy: 0.9197\n",
      "Epoch 211/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2291 - val_binary_accuracy: 0.9200\n",
      "Epoch 212/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2290 - val_binary_accuracy: 0.9200\n",
      "Epoch 213/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2290 - val_binary_accuracy: 0.9203\n",
      "Epoch 214/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2290 - val_binary_accuracy: 0.9203\n",
      "Epoch 215/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2290 - val_binary_accuracy: 0.9203\n",
      "Epoch 216/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2049 - binary_accuracy: 0.9236 - val_loss: 0.2289 - val_binary_accuracy: 0.9207\n",
      "Epoch 217/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9236 - val_loss: 0.2289 - val_binary_accuracy: 0.9207\n",
      "Epoch 218/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2048 - binary_accuracy: 0.9236 - val_loss: 0.2289 - val_binary_accuracy: 0.9207\n",
      "Epoch 219/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9236 - val_loss: 0.2289 - val_binary_accuracy: 0.9207\n",
      "Epoch 220/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9236 - val_loss: 0.2288 - val_binary_accuracy: 0.9207\n",
      "Epoch 221/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2048 - binary_accuracy: 0.9235 - val_loss: 0.2288 - val_binary_accuracy: 0.9207\n",
      "Epoch 222/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9235 - val_loss: 0.2288 - val_binary_accuracy: 0.9207\n",
      "Epoch 223/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2048 - binary_accuracy: 0.9234 - val_loss: 0.2288 - val_binary_accuracy: 0.9207\n",
      "Epoch 224/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2048 - binary_accuracy: 0.9234 - val_loss: 0.2288 - val_binary_accuracy: 0.9207\n",
      "Epoch 225/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9234 - val_loss: 0.2287 - val_binary_accuracy: 0.9207\n",
      "Epoch 226/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9234 - val_loss: 0.2287 - val_binary_accuracy: 0.9207\n",
      "Epoch 227/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9234 - val_loss: 0.2287 - val_binary_accuracy: 0.9210\n",
      "Epoch 228/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2048 - binary_accuracy: 0.9235 - val_loss: 0.2287 - val_binary_accuracy: 0.9210\n",
      "Epoch 229/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2048 - binary_accuracy: 0.9235 - val_loss: 0.2287 - val_binary_accuracy: 0.9210\n",
      "Epoch 230/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9235 - val_loss: 0.2287 - val_binary_accuracy: 0.9210\n",
      "Epoch 231/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2287 - val_binary_accuracy: 0.9210\n",
      "Epoch 232/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9235 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 233/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 234/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 235/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 236/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 237/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 238/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 239/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 240/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2286 - val_binary_accuracy: 0.9210\n",
      "Epoch 241/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2285 - val_binary_accuracy: 0.9210\n",
      "Epoch 242/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2285 - val_binary_accuracy: 0.9210\n",
      "Epoch 243/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2285 - val_binary_accuracy: 0.9210\n",
      "Epoch 244/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2285 - val_binary_accuracy: 0.9210\n",
      "Epoch 245/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2285 - val_binary_accuracy: 0.9207\n",
      "Epoch 246/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2285 - val_binary_accuracy: 0.9207\n",
      "Epoch 247/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2285 - val_binary_accuracy: 0.9207\n",
      "Epoch 248/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2258 - val_binary_accuracy: 0.9207\n",
      "Epoch 249/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2255 - val_binary_accuracy: 0.9207\n",
      "Epoch 250/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2254 - val_binary_accuracy: 0.9207\n",
      "Epoch 251/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2252 - val_binary_accuracy: 0.9207\n",
      "Epoch 252/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2252 - val_binary_accuracy: 0.9207\n",
      "Epoch 253/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2251 - val_binary_accuracy: 0.9213\n",
      "Epoch 254/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2251 - val_binary_accuracy: 0.9213\n",
      "Epoch 255/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2250 - val_binary_accuracy: 0.9213\n",
      "Epoch 256/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9237 - val_loss: 0.2250 - val_binary_accuracy: 0.9213\n",
      "Epoch 257/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2047 - binary_accuracy: 0.9236 - val_loss: 0.2249 - val_binary_accuracy: 0.9213\n",
      "Epoch 258/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9236 - val_loss: 0.2249 - val_binary_accuracy: 0.9213\n",
      "Epoch 259/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2249 - val_binary_accuracy: 0.9213\n",
      "Epoch 260/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2248 - val_binary_accuracy: 0.9213\n",
      "Epoch 261/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2248 - val_binary_accuracy: 0.9213\n",
      "Epoch 262/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2248 - val_binary_accuracy: 0.9213\n",
      "Epoch 263/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2247 - val_binary_accuracy: 0.9213\n",
      "Epoch 264/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2247 - val_binary_accuracy: 0.9213\n",
      "Epoch 265/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2247 - val_binary_accuracy: 0.9213\n",
      "Epoch 266/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2247 - val_binary_accuracy: 0.9213\n",
      "Epoch 267/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2247 - val_binary_accuracy: 0.9213\n",
      "Epoch 268/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 269/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 270/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 271/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 272/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 273/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 274/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2246 - val_binary_accuracy: 0.9213\n",
      "Epoch 275/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 276/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 277/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 278/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 279/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 280/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 281/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 282/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 283/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2245 - val_binary_accuracy: 0.9213\n",
      "Epoch 284/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 285/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9238 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 286/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 287/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 288/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 289/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 290/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 291/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 292/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 293/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 294/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 295/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 296/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 297/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 298/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2244 - val_binary_accuracy: 0.9213\n",
      "Epoch 299/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 300/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 301/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 302/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 303/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 304/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 305/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 306/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 307/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 308/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 309/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 310/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 311/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 312/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 313/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 314/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 315/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 316/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 317/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 318/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 319/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 320/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 321/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 322/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 323/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2046 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 324/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2243 - val_binary_accuracy: 0.9213\n",
      "Epoch 325/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 326/500\n",
      "10/10 [==============================] - 0s 19ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 327/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 328/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 329/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 330/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 331/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 332/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 333/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 334/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 335/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 336/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 337/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 338/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 339/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 340/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 341/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 342/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 343/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 344/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 345/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 346/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 347/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 348/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 349/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 350/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 351/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 352/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 353/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 354/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 355/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 356/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 357/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 358/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 359/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 360/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 361/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 362/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 363/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 364/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 365/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 366/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 367/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 368/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 369/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 370/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 371/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 372/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 373/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 374/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 375/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 376/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 377/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 378/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 379/500\n",
      "10/10 [==============================] - 0s 21ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 380/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 381/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 382/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Epoch 383/500\n",
      "10/10 [==============================] - 0s 20ms/step - loss: 0.2045 - binary_accuracy: 0.9237 - val_loss: 0.2242 - val_binary_accuracy: 0.9213\n",
      "Restoring model weights from the end of the best epoch\n",
      "Epoch 00383: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2dcac512b0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer = opt,\n",
    "    loss = 'binary_crossentropy',\n",
    "    metrics = ['binary_accuracy']\n",
    ")\n",
    "stop = EarlyStopping(patience = 15, verbose =1, restore_best_weights= True)\n",
    "\n",
    "model.fit([X_train_s2, s2i1, s2i2], y_train_s2,\n",
    "    steps_per_epoch=10,\n",
    "    validation_split = 0.1,\n",
    "    validation_steps = 2,\n",
    "    callbacks = [stop],\n",
    "    epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code should get loss smaller than the ones below, otherwise early stop indicates the minimum hasn't been found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20897613898377027 0.2077384282095154\n"
     ]
    }
   ],
   "source": [
    "print(log_loss(y_train_s2, s2i1), log_loss(y_train_s2, s2i2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason Keras gets a worse result than just using previous predictions would get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sVi1 = pipeline.predict_proba(X_val)[:, 1]  #stage - validation -  input 1\n",
    "sVi2 = bst1.predict(xgb.DMatrix(X_val), ntree_limit=bst1.best_ntree_limit) #stage - validation - input 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code below is only for testing if at the beginning a validation set has been set apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan 0.20107871929278218 0.17653931730318217\n",
      "0.9237854611514358 0.9023875277015142 0.9285227995386464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1817: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/metrics/classification.py:1817: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict([X_val, sVi1, sVi2])\n",
    "print(log_loss(y_val, pred), log_loss(y_val, sVi1), log_loss(y_val, sVi2))\n",
    "print(roc_auc_score(y_val, pred), roc_auc_score(y_val, sVi1), roc_auc_score(y_val, sVi2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " And here for the final predicition:\n",
    "\n",
    "*Note for myself - diminishing sets (to split for s1 and s2) can be circumvented by retraining a few times and uploading averaged out results.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "efcdd12e19f4ecb2b55b6f0d5671906831266377"
   },
   "outputs": [],
   "source": [
    "sTi1 = pipeline.predict_proba(X_test)[:, 1]  #stage - test -  input 1\n",
    "sTi2 = bst1.predict(xgb.DMatrix(X_test), ntree_limit=bst1.best_ntree_limit) #stage - test - input 2\n",
    "pred = model.predict([X_test, sTi1, sTi2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "ec8478ee70276b59984bdaeddf0d10b3790abe4c"
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = pred\n",
    "submission.to_csv('submission0.csv', index=False)\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = sTi1\n",
    "submission.to_csv('submission1.csv', index=False)\n",
    "submission = pd.read_csv('../input/sample_submission.csv')\n",
    "submission['target'] = sTi2\n",
    "submission.to_csv('submission2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f7bb167d6e18d9a79a7ad8138d01357c7f7fcc90"
   },
   "source": [
    "The end result got so bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
