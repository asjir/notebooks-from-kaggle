{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.csv', 'sample_submission.csv', 'test.csv']\n",
      "(250, 302)\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"../input\"))\n",
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "sub = pd.read_csv('../input/sample_submission.csv')\n",
    "print(train.shape)\n",
    "X_a = train.drop(['id', 'target'], axis=1)\n",
    "y_a = train['target']\n",
    "X_test = test.drop(['id'], axis=1)\n",
    "# Any results you write to the current directory are saved as output.\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version two uses hyperparameters found by skopt search, let's see how it performs.\n",
    "\n",
    "C=10 made no sense for linear regression, no idea what was wrong with the search that it gave me that as the answer though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as ttsplit\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm import trange\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbc = GaussianNB()\n",
    "nbc.fit(X_a, y_a)\n",
    "sub.target = nbc.predict_proba(X_test)\n",
    "sub.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective':'binary:logistic', 'eval_metric':['auc'], 'eta':0.015, 'max_depth':1, 'colsample_bytree':1, 'subsample':0.5, 'n_estimators':30, 'tree_method': 'gpu_hist', 'verbose':0\n",
    "        }\n",
    "\n",
    "num_round = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [01:18<00:00,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7320484419244824 0.7464131909874508 0.7880944658765843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scoresa = []\n",
    "scoresg = []\n",
    "scores1 = []\n",
    "scores2 = []\n",
    "scores3 = []\n",
    "scores4 = []\n",
    "scores5 = []\n",
    "precision = 10\n",
    "for i in trange(500):\n",
    "    X_train, X_val, y_train, y_val = ttsplit(X_a, y_a, test_size = 0.2)\n",
    "#    knc = KNeighborsClassifier(n_neighbors=100, weights='distance')\n",
    "#    knc.fit(X_train, y_train)\n",
    "#    pred1 = knc.predict_proba(X_val)[:,1]\n",
    "#    scores1+=[roc_auc_score(y_val, pred1)]\n",
    "\n",
    "    nbc = GaussianNB()\n",
    "    nbc.fit(X_train, y_train)\n",
    "    pred2 = nbc.predict_proba(X_val)[:,1]\n",
    "    scores2+=[roc_auc_score(y_val, pred2)]\n",
    "    \n",
    "    lr = LogisticRegression(solver = 'liblinear', C = .1, penalty = 'l1')\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred3 = lr.predict_proba(X_val)[:,1]\n",
    "    scores3+=[roc_auc_score(y_val, pred3)]\n",
    "    \n",
    "#    ab = AdaBoostClassifier(base_estimator=None, n_estimators=3, learning_rate=1.0)\n",
    "#    ab.fit(X_train, y_train)\n",
    "#    pred4 = ab.predict_proba(X_val)[:,1]\n",
    "#    scores4+=[roc_auc_score(y_val, pred4)]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dval = xgb.DMatrix(X_val, y_val)\n",
    "    evallist = [ (dtrain, 'train'), (dval, 'eval')]\n",
    "    bst1 = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "    pred5 = bst1.predict(xgb.DMatrix(X_val), ntree_limit=bst1.best_ntree_limit)\n",
    "    scores5+=[roc_auc_score(y_val, pred5)]\n",
    "    \n",
    "    generalA = np.zeros((precision,precision)) #all possible arithmetic means\n",
    "    for j in range(precision):\n",
    "        for k in range(precision-j):\n",
    "            generalA[j,k] = ( roc_auc_score(y_val,( (pred2*j+pred5*k+pred3*(precision-j-k))/precision )))\n",
    "\n",
    "    scoresa+=[generalA]\n",
    "    \n",
    "\n",
    "print(np.average(np.array(scores2)),np.average(np.array(scores5)),np.average(np.array(scores3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95236165 0.96849242 0.98332632 1.00236587 1.028396   1.06559851\n",
      "  1.10752682 1.13938098 1.15167401 1.07380012]\n",
      " [1.30548179 1.34081685 1.37783801 1.41415831 1.45322942 1.4836449\n",
      "  1.47786269 1.41711457 1.23562998 0.        ]\n",
      " [1.38015156 1.37953223 1.36553318 1.35246415 1.3169259  1.25374543\n",
      "  1.15003533 0.9378358  0.         0.        ]\n",
      " [1.2795745  1.24852755 1.20003456 1.15134236 1.07144613 0.96443922\n",
      "  0.76586509 0.         0.         0.        ]\n",
      " [1.12935965 1.0744036  1.01317822 0.93772971 0.82747901 0.62653548\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.96750086 0.91123843 0.82636173 0.7178132  0.51941467 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.82011523 0.73707848 0.61494273 0.43063339 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.65421518 0.5261833  0.34652201 0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.44794158 0.26564259 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.18756413 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scoresa = np.array(scoresa)\n",
    "plot = np.maximum(np.average(scoresa, axis=0)-0.75, 0)*25\n",
    "plt.imshow(plot)\n",
    "print(plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So based on above picture I can slightly limit my search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [03:26<00:00,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.730274717859264 0.7449240687952038 0.788327592355937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scoresa = []\n",
    "scoresg = []\n",
    "scores1 = []\n",
    "scores2 = []\n",
    "scores3 = []\n",
    "scores4 = []\n",
    "scores5 = []\n",
    "precision = 100\n",
    "for i in trange(500):\n",
    "    X_train, X_val, y_train, y_val = ttsplit(X_a, y_a, test_size = 0.2)\n",
    "#    knc = KNeighborsClassifier(n_neighbors=100, weights='distance')       not everything worked well enough to make sense including it in the search\n",
    "#    knc.fit(X_train, y_train)\n",
    "#    pred1 = knc.predict_proba(X_val)[:,1]\n",
    "#    scores1+=[roc_auc_score(y_val, pred1)]\n",
    "\n",
    "    nbc = GaussianNB()\n",
    "    nbc.fit(X_train, y_train)\n",
    "    pred2 = nbc.predict_proba(X_val)[:,1]\n",
    "    scores2+=[roc_auc_score(y_val, pred2)]\n",
    "    \n",
    "    lr = LogisticRegression(solver = 'liblinear', C = 0.1, penalty = 'l1')\n",
    "    lr.fit(X_train, y_train)\n",
    "    pred3 = lr.predict_proba(X_val)[:,1]\n",
    "    scores3+=[roc_auc_score(y_val, pred3)]\n",
    "    \n",
    "#    ab = AdaBoostClassifier(base_estimator=None, n_estimators=3, learning_rate=1.0)\n",
    "#    ab.fit(X_train, y_train)\n",
    "#    pred4 = ab.predict_proba(X_val)[:,1]\n",
    "#    scores4+=[roc_auc_score(y_val, pred4)]\n",
    "    \n",
    "    dtrain = xgb.DMatrix(X_train, y_train)\n",
    "    dval = xgb.DMatrix(X_val, y_val)\n",
    "    evallist = [ (dtrain, 'train'), (dval, 'eval')]\n",
    "    bst1 = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "    pred5 = bst1.predict(xgb.DMatrix(X_val), ntree_limit=bst1.best_ntree_limit)\n",
    "    scores5+=[roc_auc_score(y_val, pred5)]\n",
    "    \n",
    "    generalA = np.zeros((precision,precision)) #all possible arithmetic means\n",
    "    for j in range(0,20):\n",
    "        for k in range(40,60):\n",
    "            generalA[j,k] = ( roc_auc_score(y_val,( (pred2*j+pred5*k+pred3*(precision-j-k))/precision )))\n",
    "\n",
    "    scoresa+=[generalA]\n",
    "    \n",
    "\n",
    "print(np.average(np.array(scores2)),np.average(np.array(scores5)),np.average(np.array(scores3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.80945555499377"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scoresa = np.array(scoresa)\n",
    "print(scoresa[0:20,40:60])\n",
    "plot = np.maximum(np.average(scoresa[40:60,0:20], axis=0)-0.75, 0)*25\n",
    "plt.imshow(plot)\n",
    "\n",
    "np.max(np.average(scoresa, axis = 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So something like 0.1, 0.55, 0.35 should be close enough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = ttsplit(X_a, y_a, test_size = 0.2)\n",
    "nbc = GaussianNB()\n",
    "nbc.fit(X_a, y_a)\n",
    "pred2 = nbc.predict_proba(X_test)[:,1]\n",
    "\n",
    "lr = LogisticRegression(solver = 'liblinear', C = 0.1, penalty = 'l1')\n",
    "lr.fit(X_a, y_a)\n",
    "pred3 = lr.predict_proba(X_test)[:,1]\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dval = xgb.DMatrix(X_val, y_val)\n",
    "evallist = [ (dtrain, 'train'), (dval, 'eval')]\n",
    "bst1 = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds = 10, verbose_eval = False)\n",
    "pred5 = bst1.predict(xgb.DMatrix(X_test), ntree_limit=bst1.best_ntree_limit)\n",
    "\n",
    "pred = pred2*0.1+pred3*0.35+pred5*0.55\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.target = pred\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
